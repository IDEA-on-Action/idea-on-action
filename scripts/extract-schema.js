/**
 * Supabase Schema Extractor
 * í˜„ìž¬ ë°ì´í„°ë² ì´ìŠ¤ì˜ ì „ì²´ ìŠ¤í‚¤ë§ˆë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
 */

import { createClient } from '@supabase/supabase-js'
import { writeFileSync } from 'fs'
import { fileURLToPath } from 'url'
import { dirname, join } from 'path'

const __filename = fileURLToPath(import.meta.url)
const __dirname = dirname(__filename)

// í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (Vite ë° Next.js í˜•ì‹ ëª¨ë‘ ì§€ì›)
const SUPABASE_URL = process.env.VITE_SUPABASE_URL
  || process.env.NEXT_PUBLIC_SUPABASE_URL
  || 'https://zykjdneewbzyazfukzyg.supabase.co'

const SUPABASE_ANON_KEY = process.env.VITE_SUPABASE_ANON_KEY
  || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY

if (!SUPABASE_ANON_KEY) {
  console.error('âŒ Supabase ANON KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
  console.log('ðŸ’¡ .env.local íŒŒì¼ì„ í™•ì¸í•˜ê±°ë‚˜ ì§ì ‘ KEYë¥¼ ìž…ë ¥í•˜ì„¸ìš”.')
  process.exit(1)
}

const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY)

async function extractSchema() {
  console.log('ðŸ” Supabase ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ ì‹œìž‘...\n')

  try {
    // 1. ëª¨ë“  í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    console.log('ðŸ“Š Step 1: í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ...')
    const { data: tables, error: tablesError } = await supabase.rpc('get_tables')

    if (tablesError) {
      // RPC í•¨ìˆ˜ê°€ ì—†ì„ ê²½ìš° ëŒ€ì²´ ë°©ë²• ì‚¬ìš©
      console.log('âš ï¸  RPC í•¨ìˆ˜ ì—†ìŒ. SQL ì§ì ‘ ì‹¤í–‰ ë°©ì‹ìœ¼ë¡œ ë³€ê²½...\n')
      await extractSchemaDirectSQL()
      return
    }

    if (!tables || tables.length === 0) {
      console.log('âš ï¸  í…Œì´ë¸”ì´ ì—†ê±°ë‚˜ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.')
      return
    }

    console.log(`âœ… ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: ${tables.length}\n`)

    // 2. ê° í…Œì´ë¸”ì˜ ì»¬ëŸ¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    const schemaInfo = {
      extracted_at: new Date().toISOString(),
      database_url: SUPABASE_URL,
      tables: []
    }

    for (const table of tables) {
      console.log(`ðŸ“‹ í…Œì´ë¸” ë¶„ì„ ì¤‘: ${table.table_name}`)

      const { data: columns, error: columnsError } = await supabase
        .rpc('get_table_columns', { table_name: table.table_name })

      if (columnsError) {
        console.error(`  âŒ ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: ${columnsError.message}`)
        continue
      }

      schemaInfo.tables.push({
        name: table.table_name,
        schema: table.table_schema || 'public',
        columns: columns || [],
        row_count: table.row_count || 0
      })

      console.log(`  âœ… ì»¬ëŸ¼ ìˆ˜: ${columns?.length || 0}`)
    }

    // 3. ê²°ê³¼ ì €ìž¥
    const outputPath = join(__dirname, '..', 'docs', 'database', 'current-schema.json')
    writeFileSync(outputPath, JSON.stringify(schemaInfo, null, 2), 'utf-8')

    console.log(`\nâœ… ìŠ¤í‚¤ë§ˆ ì •ë³´ ì €ìž¥ ì™„ë£Œ: ${outputPath}`)
    console.log(`ðŸ“Š ì´ ${schemaInfo.tables.length}ê°œ í…Œì´ë¸” ì¶”ì¶œ ì™„ë£Œ\n`)

    // 4. ìš”ì•½ ì¶œë ¥
    console.log('ðŸ“Œ í…Œì´ë¸” ìš”ì•½:')
    schemaInfo.tables.forEach(table => {
      console.log(`  - ${table.name} (${table.columns.length} columns)`)
    })

  } catch (error) {
    console.error('âŒ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error.message)
    process.exit(1)
  }
}

/**
 * SQL ì§ì ‘ ì‹¤í–‰ ë°©ì‹ (RPC í•¨ìˆ˜ ì—†ì„ ë•Œ ëŒ€ì²´)
 */
async function extractSchemaDirectSQL() {
  console.log('ðŸ“Š SQL ì§ì ‘ ì‹¤í–‰ ë°©ì‹ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ...\n')

  const queries = {
    tables: `
      SELECT
        table_name,
        table_schema
      FROM information_schema.tables
      WHERE table_schema = 'public'
      AND table_type = 'BASE TABLE'
      ORDER BY table_name;
    `,
    columns: (tableName) => `
      SELECT
        column_name,
        data_type,
        is_nullable,
        column_default,
        character_maximum_length
      FROM information_schema.columns
      WHERE table_schema = 'public'
      AND table_name = '${tableName}'
      ORDER BY ordinal_position;
    `,
    foreignKeys: `
      SELECT
        tc.table_name,
        kcu.column_name,
        ccu.table_name AS foreign_table_name,
        ccu.column_name AS foreign_column_name,
        tc.constraint_name
      FROM information_schema.table_constraints AS tc
      JOIN information_schema.key_column_usage AS kcu
        ON tc.constraint_name = kcu.constraint_name
      JOIN information_schema.constraint_column_usage AS ccu
        ON ccu.constraint_name = tc.constraint_name
      WHERE tc.constraint_type = 'FOREIGN KEY'
      AND tc.table_schema = 'public';
    `
  }

  try {
    // í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (Supabaseì—ì„œ ì§ì ‘ ì¡°íšŒ)
    const { data: publicTables, error: tablesError } = await supabase
      .from('information_schema.tables')
      .select('table_name, table_schema')
      .eq('table_schema', 'public')
      .eq('table_type', 'BASE TABLE')

    if (tablesError) {
      console.log('âš ï¸  information_schema ì ‘ê·¼ ë¶ˆê°€. ì•Œë ¤ì§„ í…Œì´ë¸”ë¡œ ì‹œë„...\n')
      await extractKnownTables()
      return
    }

    console.log(`âœ… ë°œê²¬ëœ í…Œì´ë¸”: ${publicTables?.length || 0}ê°œ\n`)

    const schemaInfo = {
      extracted_at: new Date().toISOString(),
      database_url: SUPABASE_URL,
      method: 'direct_sql',
      tables: []
    }

    // ê° í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
    for (const table of publicTables || []) {
      console.log(`ðŸ“‹ ${table.table_name} ë¶„ì„ ì¤‘...`)

      const { data: rows } = await supabase
        .from(table.table_name)
        .select('*', { count: 'exact', head: true })

      schemaInfo.tables.push({
        name: table.table_name,
        schema: table.table_schema,
        estimated_rows: rows?.length || 0
      })
    }

    // ê²°ê³¼ ì €ìž¥
    const outputPath = join(__dirname, '..', 'docs', 'database', 'current-schema.json')
    writeFileSync(outputPath, JSON.stringify(schemaInfo, null, 2), 'utf-8')

    console.log(`\nâœ… ìŠ¤í‚¤ë§ˆ ì •ë³´ ì €ìž¥ ì™„ë£Œ: ${outputPath}\n`)

  } catch (error) {
    console.error('âŒ SQL ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:', error.message)
    await extractKnownTables()
  }
}

/**
 * ì•Œë ¤ì§„ í…Œì´ë¸” ì§ì ‘ ì¡°íšŒ (ìµœí›„ ìˆ˜ë‹¨)
 */
async function extractKnownTables() {
  console.log('ðŸ“Š ì•Œë ¤ì§„ í…Œì´ë¸” ëª©ë¡ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ...\n')

  const knownTables = [
    'services',
    'service_categories',
    'carts',
    'orders',
    'order_items',
    'payments',
    'user_profiles',
    'user_roles',
    'posts',
    'post_tags',
    'gallery',
    'metrics',
    'chat_messages',
    'analytics_events'
  ]

  const schemaInfo = {
    extracted_at: new Date().toISOString(),
    database_url: SUPABASE_URL,
    method: 'known_tables',
    note: 'This is a fallback method. Some tables might be missing.',
    tables: []
  }

  for (const tableName of knownTables) {
    try {
      console.log(`ðŸ” ${tableName} í™•ì¸ ì¤‘...`)

      const { data, error, count } = await supabase
        .from(tableName)
        .select('*', { count: 'exact', head: true })

      if (error) {
        console.log(`  âš ï¸  í…Œì´ë¸” ì—†ìŒ ë˜ëŠ” ì ‘ê·¼ ë¶ˆê°€`)
        continue
      }

      // ì²« ë²ˆì§¸ í–‰ìœ¼ë¡œ ì»¬ëŸ¼ êµ¬ì¡° íŒŒì•…
      const { data: sample } = await supabase
        .from(tableName)
        .select('*')
        .limit(1)
        .single()

      const columns = sample ? Object.keys(sample).map(key => ({
        name: key,
        type: typeof sample[key],
        sample_value: sample[key]
      })) : []

      schemaInfo.tables.push({
        name: tableName,
        exists: true,
        row_count: count || 0,
        columns
      })

      console.log(`  âœ… ì¡´ìž¬ (${count || 0}ê°œ í–‰, ${columns.length}ê°œ ì»¬ëŸ¼)`)

    } catch (err) {
      console.log(`  âš ï¸  ì˜¤ë¥˜: ${err.message}`)
    }
  }

  // ê²°ê³¼ ì €ìž¥
  const outputPath = join(__dirname, '..', 'docs', 'database', 'current-schema.json')
  writeFileSync(outputPath, JSON.stringify(schemaInfo, null, 2), 'utf-8')

  console.log(`\nâœ… ìŠ¤í‚¤ë§ˆ ì •ë³´ ì €ìž¥ ì™„ë£Œ: ${outputPath}`)
  console.log(`ðŸ“Š ë°œê²¬ëœ í…Œì´ë¸”: ${schemaInfo.tables.length}ê°œ\n`)

  // ìš”ì•½ ì¶œë ¥
  console.log('ðŸ“Œ ì¡´ìž¬í•˜ëŠ” í…Œì´ë¸”:')
  schemaInfo.tables.forEach(table => {
    console.log(`  - ${table.name} (${table.row_count} rows, ${table.columns?.length || 0} columns)`)
  })
}

// ì‹¤í–‰
extractSchema()
